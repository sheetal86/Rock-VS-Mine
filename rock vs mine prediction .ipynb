{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660e2c27",
   "metadata": {},
   "source": [
    "### Project :- Rock VS Mine \n",
    "   1. Rock :- The hard, solid material that forms part of the surface of the earth\n",
    "   2. Mine:- A bomb that is hidden under the ground or under water and explodes when somebody/something touches it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cdd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries \n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv, set_option\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3d90b",
   "metadata": {},
   "source": [
    "### Data Collection , Data Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc29085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_data= pd.read_csv(\"sonar data.csv\", header=None)\n",
    "#with the help of header=none , we are accessing features/columns by its number series :1,2,...60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75f5209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5b25c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f41b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are splitting the dependent and independent features in X and Y labels\n",
    "# In X we are dropping the column no 60 which is categorical feature as well as dependent feature\n",
    "# as we know that 60 th column is dependent feature , targeted feautre , so we are coping it into Y \n",
    "X= sonar_data.drop(columns=60,axis=1)\n",
    "Y= sonar_data[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9171fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0       1       2       3       4       5       6       7       8   \\\n",
      "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
      "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
      "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
      "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
      "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
      "\n",
      "         9   ...      50      51      52      53      54      55      56  \\\n",
      "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
      "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
      "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
      "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
      "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
      "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
      "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
      "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
      "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
      "\n",
      "         57      58      59  \n",
      "0    0.0084  0.0090  0.0032  \n",
      "1    0.0049  0.0052  0.0044  \n",
      "2    0.0164  0.0095  0.0078  \n",
      "3    0.0044  0.0040  0.0117  \n",
      "4    0.0048  0.0107  0.0094  \n",
      "..      ...     ...     ...  \n",
      "203  0.0115  0.0193  0.0157  \n",
      "204  0.0032  0.0062  0.0067  \n",
      "205  0.0138  0.0077  0.0031  \n",
      "206  0.0079  0.0036  0.0048  \n",
      "207  0.0036  0.0061  0.0115  \n",
      "\n",
      "[208 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "#CHECKING SHAPE that X contains all numerical features as well as independent features \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec98039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      R\n",
      "1      R\n",
      "2      R\n",
      "3      R\n",
      "4      R\n",
      "      ..\n",
      "203    M\n",
      "204    M\n",
      "205    M\n",
      "206    M\n",
      "207    M\n",
      "Name: 60, Length: 208, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#checking the shape of Y , it contains only dependent features or you can say that targeted feature\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c687b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are spliting both dependent AND independent features into train test split \n",
    "#stratify means distribute both rock and mine into equal parts in train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test, Y_train, Y_test= train_test_split(X,Y, test_size=0.1, stratify=Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d5009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187, 60) (21,) (187,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_test.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605b50a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important feature using ExtraTreesRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "selection = ExtraTreesClassifier()\n",
    "selection.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c1a2347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01594176 0.01173686 0.00865006 0.01845109 0.01084644 0.01168021\n",
      " 0.00858339 0.01369293 0.02945669 0.03127819 0.04635844 0.04880919\n",
      " 0.01916755 0.0098183  0.01270799 0.01385831 0.01913801 0.01416681\n",
      " 0.01330519 0.0212646  0.02745468 0.01495652 0.01485343 0.01138871\n",
      " 0.01019291 0.01278013 0.02032684 0.01743875 0.01392938 0.00938808\n",
      " 0.0173961  0.01123263 0.01160551 0.01246915 0.01832232 0.02931801\n",
      " 0.02207542 0.01255263 0.01411322 0.01316516 0.0100853  0.01183293\n",
      " 0.01522186 0.02176292 0.02373829 0.0194361  0.02434454 0.02368207\n",
      " 0.02653168 0.0082185  0.01617551 0.01414826 0.0100202  0.01300228\n",
      " 0.01034072 0.01086074 0.01037882 0.01387223 0.01143642 0.01103904]\n"
     ]
    }
   ],
   "source": [
    "print(selection.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9026572",
   "metadata": {},
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "plt.figure(figsize = (12,8))\n",
    "feat_importances = pd.Series(selection.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dad819",
   "metadata": {},
   "source": [
    "observation: as we can see that, 11 th feature affect target feature most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d55dd7",
   "metadata": {},
   "source": [
    "# NOTE:- \n",
    "Here if we are training our dataset on any random model then you can see the accuracy of model, and if we check by testing in which model our dataset is getting higher accuracy . \n",
    "\n",
    "1. Now first we will use random,  model evaluation , and we will fit our dataset on to that model , and check the accuracy our dataset will get.\n",
    "2. Then we will try the second method which is to check  in which model our dataset is having higher accuracy, then we will fit into that model ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f201ff",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6cf53",
   "metadata": {},
   "source": [
    "## Model Training --> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64000c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model= LogisticRegression()\n",
    "#here we are using logistic regression because we have the scenerio of yes or no --> rock or mine, logistic regression is basically is for these kind of cases  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8771468e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b311cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_predict= model.predict(X_train)\n",
    "training_data_accuracy =accuracy_score(X_train_predict, Y_train)\n",
    "#we use metrics for model evaluation, (means checking whether our model is giving us gud accuracy or not)\n",
    "# here we did is :, we are predicting on training data, and checking the accuract on training data ,\n",
    "# after gud accuracy on training data we apply it on test data, that it gives us gud accuracy or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f222bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on training data is :  0.8342245989304813\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score on training data is : \", training_data_accuracy)\n",
    "#as here on traning data it is giving us gud accuracy , so now we apply on test also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c71a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score on test data \n",
    " \n",
    "\n",
    "X_test_predict= model.predict(X_test)\n",
    "test_data_accuracy =accuracy_score(X_test_predict, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35b1cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on test data is :  0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score on test data is : \", test_data_accuracy)\n",
    "# we can see that it is giving us accuracy score of 76 on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e564509",
   "metadata": {},
   "source": [
    "## as we can see that this model is giving us the accuracy of 76% \n",
    "-->see if we fit our dataset into that model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ded79e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "The object is a mine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_data = (0.0307,0.0523,0.0653,0.0521,0.0611,0.0577,0.0665,0.0664,0.1460,0.2792,0.3877,0.4992,0.4981,0.4972,0.5607,0.7339,0.8230,0.9173,0.9975,0.9911,0.8240,0.6498,0.5980,0.4862,0.3150,0.1543,0.0989,0.0284,0.1008,0.2636,0.2694,0.2930,0.2925,0.3998,0.3660,0.3172,0.4609,0.4374,0.1820,0.3376,0.6202,0.4448,0.1863,0.1420,0.0589,0.0576,0.0672,0.0269,0.0245,0.0190,0.0063,0.0321,0.0189,0.0137,0.0277,0.0152,0.0052,0.0121,0.0124,0.0055)\n",
    "\n",
    "# changing the input_data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the np array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]=='R'):\n",
    "  print('The object is a Rock')\n",
    "else:\n",
    "  print('The object is a mine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec270c3",
   "metadata": {},
   "source": [
    "### Try second method , model selection , try to fit in some model, the which model gives us the higher the accuracy, we predict using that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083d2f4",
   "metadata": {},
   "source": [
    "## Model Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e80b51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST OPTIONS\n",
    "num_folds=10\n",
    "seed=7\n",
    "scoring='accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c0ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check some algorithms\n",
    "models=[]\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('CART',DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994c9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.770760 (0.085380)\n",
      "LDA: 0.733333 (0.090679)\n",
      "KNN: 0.775439 (0.100347)\n",
      "CART: 0.743567 (0.090521)\n",
      "NB: 0.685088 (0.093841)\n",
      "SVM: 0.764620 (0.076195)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c6ee17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAGQCAYAAACdwQhXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaDElEQVR4nO3df7RdZX3n8fenCT+mFTApUSsgOBVtKCrWjE7VKlTtoHWgaquJOkVXKp1ZFTuobbUwEplJbbtqtVocxxZr1RJAO7hwDRXbipVYO0NokSWgiKAlqDWQIFpEA37nj3OiJ5d7ySGc3O+5975fa52Vs89+zt7f/WTf+7nPs/c9N1WFJEnq80PdBUiStNQZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYS0qS9yb5H/to2y9N8rH7WH98kq37Yt8LXZLfTvKn3XVIXQxjLUpJPpFkR5ID5mufVfUXVfVzIzVUkkfN1/4z8Ookn03yr0m2JvlgksfOVw17q6p+p6p+pbsOqYthrEUnyVHAzwAFnDRP+1w+H/vZgz8Cfh14NbASeDTwYeDnG2vaoynpO6mVYazF6JeBfwDeC5xyXw2T/GaSryb5SpJfGR3NJjkkyfuSbEvy5SRnJvmh4bqXJ/lUkrcmuQ3YMHxt83D9J4e7+EySbyV58cg+X5vk68P9vmLk9fcmeWeSvxq+51NJHpbkbcNR/ueSPGGO4zga+DVgXVV9vKq+U1V3Dkfrv3s/j+f2JDcmecrw9ZuH9Z4yo9Z3JfnrJN9M8ndJjhxZ/0fD992R5MokPzOybkOSDyX5QJI7gJcPX/vAcP2Bw3W3DWu5IslDh+senuTiJNuT3JDklTO2e+HwGL+Z5Joka+7r/1+aFoaxFqNfBv5i+PgPu76Rz5TkROA1wLOARwHHz2jyDuAQ4N8Czxhu9xUj658M3Ag8FNg4+saqevrw6eOr6kFVdcFw+WHDbR4GrAfOSbJi5K0vAs4EDgW+A3wa+Mfh8oeAP5zjmJ8JbK2q/zfH+nGP52rgR4HzgPOBf8egb14G/HGSB420fynw34e1XcWgv3e5AjiOwQj9POCDSQ4cWX/y8HgePON9MPgB6hDgiGEt/xn49nDd+cBW4OHALwK/k+RnR9570rDNg4GLgT+euzuk6WEYa1FJ8jTgSODCqroS+CLwkjmavwj4s6q6pqruBDaMbGcZsBZ4Q1V9s6q+BLwF+E8j7/9KVb2jqu6uqm8znp3A2VW1s6ouAb4FPGZk/UVVdWVV3QVcBNxVVe+rqnuAC4BZR8YMQuurc+10zOO5qar+bGRfRwxr/U5VfQz4LoNg3uX/VNUnq+o7wBnATyc5AqCqPlBVtw375i3AATOO89NV9eGq+t4sfbdzeDyPqqp7hv1xx3DbTwV+q6ruqqqrgD9l8EPFLpur6pLhMbwfePxcfSJNE8NYi80pwMeq6tbh8nnMPVX9cODmkeXR54cC+wFfHnntywxGtLO1H9dtVXX3yPKdwOho819Gnn97luXRtrttF/ix+9jvOMczc19U1X3t//vHX1XfArYz6FOSvC7JdUm+keR2BiPdQ2d77yzeD1wKnD+8fPD7SfYbbnt7VX3zPo7hayPP7wQO9Jq0FgLDWItGkn/DYLT7jCRfS/I14HTg8UlmGyF9FTh8ZPmIkee3MhihHTny2iOAW0aWp+lPnv0tcPh9XCMd53jur+/313D6eiXwleH14d9k8H+xoqoeDHwDyMh75+y74azBm6rqGOApwPMYjH6/AqxMctAEj0GaCoaxFpNfAO4BjmFwvfI4YDVwObtPZe5yIfCKJKuT/DDw33atGE5zXghsTHLQ8Oak1wAfuB/1/AuD67P7XFV9AXgnsCmD32fef3gj1Nokr5/Q8cz03CRPS7I/g2vH/1BVNwMHAXcD24DlSd4IHDzuRpOckOSxw6n1Oxj8EPG94bb/Hnjz8Ngex+C6+wM5BmkqGMZaTE5hcA34n6vqa7seDG7ieenM6cqq+ivg7cBlwA0M7sCGwY1TAKcB/8rgJq3NDKa833M/6tkA/PnwjuAX7eUx3R+vZnCs5wC3M7he/nzgI8P1D/R4ZjoPOIvB9PQTGdzkBYMp5o8C1zOYRr6L+zel/zAGN3fdAVwH/B2DqWuAdcBRDEbJFwFnVdXfPIBjkKZCqqZppk3qk2Q18FnggBnXdTVDkvcyuHv7zO5apMXAkbGWtCTPT3LA8NeLfg/4iEEsab4ZxlrqfhX4OoMp3XuA/9JbjqSlyGlqSZKaOTKWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpot79rxoYceWkcddVTX7iVJmldXXnnlrVW1arZ1bWF81FFHsWXLlq7dS5I0r5J8ea51TlNLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGZtfyhCWuiSTGxbVTWxbUlaeAxjaS+NE6BJDFpJe+Q0tSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUbKwwTnJiks8nuSHJ62dZf2SSv01ydZJPJDl88qVKkrQ47TGMkywDzgGeAxwDrEtyzIxmfwC8r6oeB5wNvHnShUqStFiNMzJ+EnBDVd1YVd8FzgdOntHmGODjw+eXzbJekiTNYZwwPgy4eWR56/C1UZ8BXjB8/nzgoCQ/OnNDSU5NsiXJlm3btu1NvZIkLTqTuoHrdcAzkvwT8AzgFuCemY2q6t1Vtaaq1qxatWpCu5YkaWFbPkabW4AjRpYPH772fVX1FYYj4yQPAl5YVbdPqEZJkha1cUbGVwBHJ3lkkv2BtcDFow2SHJpk17beALxnsmVKkrR47TGMq+pu4FXApcB1wIVVdU2Ss5OcNGx2PPD5JNcDDwU27qN6JS0wSSb6kBajVFXLjtesWVNbtmxp2bc0X5LQ9TW2kNhPWgqSXFlVa2Zb5ydwSZLUzDCWJKnZOHdTLwqTvta0WKfU7CdJmn9LJozHCQWvW40fnvaVJE2O09SSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNlncXIEkaSDKxbVXVxLY1bSbZTzAdfeXIWJKmRFXt8XF/2i1EK1euJMl9PiZtT/tbuXLlxPc5kyNjSdLU2LFjx9T9MLEvfgCYyZGxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqdmi+NWmlStXsmPHjolsa1K3sK9YsYLt27dPZFuaX5M8n8BzStKeLYowXqq/l6Z9YxrPJ/CckhYzp6klSWpmGEuS1MwwlrTXxvkc4XEesOfPBx73MR+fIyxN2qK4ZiypxzReX/fauhYiR8aSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktRsrDBOcmKSzye5IcnrZ1n/iCSXJfmnJFcnee7kS5UkaXHaYxgnWQacAzwHOAZYl+SYGc3OBC6sqicAa4F3TrpQSZIWq3FGxk8CbqiqG6vqu8D5wMkz2hRw8PD5IcBXJleiJEmL2zhhfBhw88jy1uFrozYAL0uyFbgEOG22DSU5NcmWJFu2bdu2F+VKkrT4TOoGrnXAe6vqcOC5wPuT3GvbVfXuqlpTVWtWrVo1oV1LkrSwjRPGtwBHjCwfPnxt1HrgQoCq+jRwIHDoJAqUJGmxGyeMrwCOTvLIJPszuEHr4hlt/hl4JkCS1QzC2HloSZLGsMcwrqq7gVcBlwLXMbhr+pokZyc5adjstcArk3wG2AS8vKpqXxUtSdJisnycRlV1CYMbs0Zfe+PI82uBp062NEmSlgY/gUuSpGaGsSRJzcaapp52ddbBsOGQ7jJ2U2cdvOdGkiSxSMI4b7qDabtfLAm1obsKSdJC4DT1ErJy5UqSTOQBTGQ7K1eubO4VSeq3KEbGGs+OHTumcgZBkpY6w1iaYRrvQQDvQ9DSMI1ff/PxtZeukdKaNWtqy5YtE9lWkqkc8VnTnlnT+KaxLmuafx7f/JtUTUmurKo1s63zmrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVKz5d0FaP7UWQfDhkO6y9hNnXVwdwmzStJdwr2sWLGiuwTtpZUrV7Jjx46JbW8S5+eKFSvYvn37BKrRJBjGS0jedAdV1V3GbpJQG7qr2N0k+yjJ1PW55t+OHTum7jyYxh84lzKnqSVJamYYS5LUzGlqSXvN+xCkyTCMJe0170OQJsNpakmSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNxgrjJCcm+XySG5K8fpb1b01y1fBxfZLbJ16pJEmL1PI9NUiyDDgHeDawFbgiycVVde2uNlV1+kj704An7INaJWlBqrMOhg2HdJexmzrr4O4SNGKPYQw8Cbihqm4ESHI+cDJw7Rzt1wFnTaY8SVr48qY7qKruMnaThNrQXYV2GWea+jDg5pHlrcPX7iXJkcAjgY8/8NIkSVoaJn0D11rgQ1V1z2wrk5yaZEuSLdu2bZvwriVJWpjGCeNbgCNGlg8fvjabtcCmuTZUVe+uqjVVtWbVqlXjVylJ0iI2zjXjK4CjkzySQQivBV4ys1GSnwBWAJ+eaIVjStKx2zmtWLGiuwRJWpCW4vfzPYZxVd2d5FXApcAy4D1VdU2Ss4EtVXXxsOla4PxquEthUrtMMnU3WUjSUrJUv5+PMzKmqi4BLpnx2htnLG+YXFmSJC0dfgKXJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVKzsf6esRaPJN0l7GbFihXdJegB8pySHjjDeAmpqoltK8lEt6eFaVLngOeTljqnqSVJaubIWNpL407PjtPOUaG0tBnG0l4yQCVNitPUkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc2WdxcwX5JMtF1VPZBypCXDrz1N2mI8p5ZMGE9DZ0tLkV97mrTFeE45TS1JUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVKzscI4yYlJPp/khiSvn6PNi5Jcm+SaJOdNtkxJkhav5XtqkGQZcA7wbGArcEWSi6vq2pE2RwNvAJ5aVTuSPGRfFSxJ0mKzxzAGngTcUFU3AiQ5HzgZuHakzSuBc6pqB0BVfX3ShUrSQpaku4TdrFixorsEjRgnjA8Dbh5Z3go8eUabRwMk+RSwDNhQVR+duaEkpwKnAjziEY/Ym3olacGpqoltK8lEt6fpMKkbuJYDRwPHA+uAP0ny4JmNqurdVbWmqtasWrVqQruWJGlhGyeMbwGOGFk+fPjaqK3AxVW1s6puAq5nEM6SJGkPxgnjK4Cjkzwyyf7AWuDiGW0+zGBUTJJDGUxb3zi5MiVJWrz2GMZVdTfwKuBS4Drgwqq6JsnZSU4aNrsUuC3JtcBlwG9U1W37qmhJkhaTdN0IsGbNmtqyZUvLvvXAeROJ1MOvvYUryZVVtWa2dX4ClyRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSztA5s2beLYY49l2bJlHHvssWzatKm7JElTbJw/FCHpfti0aRNnnHEG5557Lk972tPYvHkz69evB2DdunXN1UmaRo6MpQnbuHEj5557LieccAL77bcfJ5xwAueeey4bN27sLk3SlPITuLSbSf/N1aX4SUHLli3jrrvuYr/99vv+azt37uTAAw/knnvuaaxMi4GfwLVw+QlcGltVTfSxFK1evZrNmzfv9trmzZtZvXp1U0WSpp1hLE3YGWecwfr167nsssvYuXMnl112GevXr+eMM87oLk3SlPIGLmnCdt2kddppp3HdddexevVqNm7c6M1bkubkNWNJWkC8Zrxwec1YkqQpZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1M4wlSWpmGEuS1MwwliSpmWEsSVIzw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc0MY0mSmhnGkiQ1W95dgCRpIMnE2lXVAy1H88gwlqQpYYAuXU5TS5LUzDCWJKmZYSxJUjPDWJKkZoaxJEnNDGNJkpoZxpIkNTOMJUlqZhhLktTMMJYkqZlhLElSM8NYkqRmhrEkSc3S9VdCkmwDvtyy87kdCtzaXcQCYV+Nx34aj/00PvtqPNPYT0dW1arZVrSF8TRKsqWq1nTXsRDYV+Oxn8ZjP43PvhrPQusnp6klSWpmGEuS1Mww3t27uwtYQOyr8dhP47GfxmdfjWdB9ZPXjCVJaubIWJKkZoaxJEnNlmwYJ/nWLK9tSHJLkquSXJtkXUdt3cbomy8k+d9JjpnR5rgkleTE+au2x2gfJXlukuuTHDnspzuTPGSOtpXkLSPLr0uyYd4Kn0dJHpbk/CRfTHJlkkuSPHq47r8muSvJISPtj0/yjeE59rkkf5DkscPlq5JsT3LT8Pnf9B3Z/Livc2XG1+PnkvzPJEvm+3mSM5Jck+TqYR+cleTNM9ocl+S64fMvJbl8xvqrknx2Puu+L0vmP+9+eGtVHQecDPyvJPs11zNN3lpVx1XV0cAFwMeTjP4C+zpg8/DfJSHJM4G3A8+pql0fYnMr8No53vId4AVJDp2P+rokCXAR8Imq+vGqeiLwBuChwybrgCuAF8x46+XDr78nAM8DDh6ec8cBFwO/MVx+1jwcRrc9nSu7vlcdAzwWeMZ8FdYpyU8zODd+qqoeBzwLuAx48Yyma4FNI8sHJTliuI3V81Hr/WEYz6GqvgDcCazormUaVdUFwMeAl8D3v/n+EvBy4NlJDuyrbn4keTrwJ8DzquqLI6veA7w4ycpZ3nY3g7s8T5+HEjudAOysqnfteqGqPlNVlyf5ceBBwJnM8YNbVX0buAo4bB5qnVbjniv7AwcCO/Z5RdPhx4Bbq+o7AFV1a1V9EtiR5Mkj7V7E7mF8IT8I7HUz1rUzjOeQ5KeAL1TV17trmWL/CPzE8PlTgJuGofQJ4Oe7iponBwAfBn6hqj43Y923GATyr8/x3nOAl45O0S5CxwJXzrFuLXA+cDnwmCQPndkgyQrgaOCT+6zCheG+zpXTk1wFfBW4vqqums/CGn0MOGJ4aeidSXbNCGxicG6R5N8D24eDql3+kh/MxPxH4CPzVfA4DON7Oz3JNcD/BTZ2FzPlMvJ8HYNvsAz/XexT1TuBvwfWz7H+7cApSQ6auaKq7gDeB7x635U31dYB51fV9xh8g/ylkXU/k+QzwC3ApVX1tY4Cp8UezpVd09QPAX4kydr5rK1LVX0LeCJwKrANuCDJyxlcOvvF4bXzmVPUALcxGD2vBa5jMPM5NQzje3trVf0k8ELg3KUw3foAPAG4LskyBv31xiRfAt4BnDhbEC0i32MwDfakJL89c2VV3Q6cB/zaHO9/G4Mg/5F9VF+3axh8w9xNkscyGPH+9fBcWcvuP7hdXlWPB34SWJ/kuH1f6tR7G/dxrlTVTuCjwNPnsaZWVXVPVX2iqs4CXgW8sKpuBm5icO38hQzCeaYLGMw2TNUUNRjGc6qqi4EtwCndtUyjJC8Efo7BSf1M4OqqOqKqjqqqIxmMeJ7fWeO+VlV3MpiOf2mS2UbIfwj8KrB8lvduZ3ANa66R9UL3ceCAJKfueiHJ4xjMGGwYnidHVdXDgYcnOXL0zVV1E/C7wG/NZ9HTaE/nyvB+jacCX5xt/WKT5DFJjh556Th+8BcANwFvBW6sqq2zvP0i4PeBS/dpkXthKYfxDyfZOvJ4zSxtzgZes5R+ZWBorr45fdevNgEvA362qrYxGNlcNGMbf8nin6re9Y3yRODMJCfNWHcrg345YI63v4XBn3lbdGrw0X7PB541/NWma4A3A8dz73PlIobX+mZ4F/D0JEftw1IXitnOlV3XjD8LLAPeOd9FNXkQ8OcZ/Prp1QzuJt8wXPdBBrMqs458q+qbVfV7VfXdean0fvDjMCVJarbURnySJE0dw1iSpGaGsSRJzQxjSZKaGcaSJDUzjCVJamYYS5LU7P8DZV0wKUZIu3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(8,6)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "297418b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()), ('LR', LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', Pipeline([('Scaler', StandardScaler()), ('LDA', LinearDiscriminantAnalysis())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsClassifier())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeClassifier())])))\n",
    "pipelines.append(('ScaledNB', Pipeline([('Scaler', StandardScaler()), ('NB', GaussianNB())])))\n",
    "pipelines.append(('ScaledSVM', Pipeline([('Scaler', StandardScaler()), ('SVM', SVC())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2acb996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.743567 (0.102648)\n",
      "ScaledLDA: 0.733333 (0.090679)\n",
      "ScaledKNN: 0.811404 (0.087106)\n",
      "ScaledCART: 0.712281 (0.101989)\n",
      "ScaledNB: 0.685088 (0.093841)\n",
      "ScaledSVM: 0.817836 (0.076896)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a091228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare scaled algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(8,6)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfebeb4",
   "metadata": {},
   "source": [
    "### observation: Algorith Tuning: KNN and SVM show as the most promising options\n",
    "after seeing the boxplot and kfold setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c5d117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KNN algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d886b789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.834503 using {'n_neighbors': 1}\n",
      "#1 0.834503 (0.072290) with: {'n_neighbors': 1}\n",
      "#2 0.823392 (0.068100) with: {'n_neighbors': 3}\n",
      "#3 0.816959 (0.079101) with: {'n_neighbors': 5}\n",
      "#4 0.769591 (0.089455) with: {'n_neighbors': 7}\n",
      "#5 0.741813 (0.127346) with: {'n_neighbors': 9}\n",
      "#6 0.731579 (0.121074) with: {'n_neighbors': 11}\n",
      "#8 0.715205 (0.155737) with: {'n_neighbors': 13}\n",
      "#7 0.716082 (0.104041) with: {'n_neighbors': 15}\n",
      "#11 0.705848 (0.092207) with: {'n_neighbors': 17}\n",
      "#10 0.711404 (0.078285) with: {'n_neighbors': 19}\n",
      "#9 0.711404 (0.088264) with: {'n_neighbors': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576b1be",
   "metadata": {},
   "source": [
    "Parameters of SVM are C and kernel. Try a number of kernels with various values of C with less bias and more bias (less than and greater than 1.0 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "523f54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM algorithm tuning\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f92b626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.849415 using {'C': 1.7, 'kernel': 'rbf'}\n",
      "#11 0.780994 (0.063450) with: {'C': 0.1, 'kernel': 'linear'}\n",
      "#40 0.546199 (0.155229) with: {'C': 0.1, 'kernel': 'poly'}\n",
      "#39 0.603801 (0.179472) with: {'C': 0.1, 'kernel': 'rbf'}\n",
      "#37 0.722515 (0.072116) with: {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "#21 0.753801 (0.072013) with: {'C': 0.3, 'kernel': 'linear'}\n",
      "#38 0.653801 (0.159721) with: {'C': 0.3, 'kernel': 'poly'}\n",
      "#19 0.754386 (0.087602) with: {'C': 0.3, 'kernel': 'rbf'}\n",
      "#13 0.759942 (0.102426) with: {'C': 0.3, 'kernel': 'sigmoid'}\n",
      "#14 0.759649 (0.075581) with: {'C': 0.5, 'kernel': 'linear'}\n",
      "#36 0.722807 (0.115708) with: {'C': 0.5, 'kernel': 'poly'}\n",
      "#9 0.781287 (0.074797) with: {'C': 0.5, 'kernel': 'rbf'}\n",
      "#17 0.754678 (0.096875) with: {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "#25 0.743567 (0.097101) with: {'C': 0.7, 'kernel': 'linear'}\n",
      "#23 0.749123 (0.120231) with: {'C': 0.7, 'kernel': 'poly'}\n",
      "#10 0.780994 (0.072529) with: {'C': 0.7, 'kernel': 'rbf'}\n",
      "#24 0.744152 (0.101013) with: {'C': 0.7, 'kernel': 'sigmoid'}\n",
      "#28 0.743275 (0.081650) with: {'C': 0.9, 'kernel': 'linear'}\n",
      "#15 0.759649 (0.113921) with: {'C': 0.9, 'kernel': 'poly'}\n",
      "#8 0.796784 (0.084959) with: {'C': 0.9, 'kernel': 'rbf'}\n",
      "#30 0.738596 (0.088120) with: {'C': 0.9, 'kernel': 'sigmoid'}\n",
      "#33 0.732749 (0.091397) with: {'C': 1.0, 'kernel': 'linear'}\n",
      "#20 0.754094 (0.119536) with: {'C': 1.0, 'kernel': 'poly'}\n",
      "#5 0.812573 (0.076856) with: {'C': 1.0, 'kernel': 'rbf'}\n",
      "#32 0.733333 (0.092666) with: {'C': 1.0, 'kernel': 'sigmoid'}\n",
      "#34 0.732456 (0.095388) with: {'C': 1.3, 'kernel': 'linear'}\n",
      "#16 0.759357 (0.110184) with: {'C': 1.3, 'kernel': 'poly'}\n",
      "#4 0.828363 (0.072146) with: {'C': 1.3, 'kernel': 'rbf'}\n",
      "#35 0.727778 (0.097034) with: {'C': 1.3, 'kernel': 'sigmoid'}\n",
      "#31 0.737719 (0.091030) with: {'C': 1.5, 'kernel': 'linear'}\n",
      "#12 0.775146 (0.093205) with: {'C': 1.5, 'kernel': 'poly'}\n",
      "#2 0.838889 (0.073373) with: {'C': 1.5, 'kernel': 'rbf'}\n",
      "#29 0.738889 (0.102306) with: {'C': 1.5, 'kernel': 'sigmoid'}\n",
      "#26 0.743275 (0.086084) with: {'C': 1.7, 'kernel': 'linear'}\n",
      "#6 0.797076 (0.092068) with: {'C': 1.7, 'kernel': 'poly'}\n",
      "#1 0.849415 (0.076776) with: {'C': 1.7, 'kernel': 'rbf'}\n",
      "#22 0.749708 (0.114329) with: {'C': 1.7, 'kernel': 'sigmoid'}\n",
      "#26 0.743275 (0.086084) with: {'C': 2.0, 'kernel': 'linear'}\n",
      "#6 0.797076 (0.092068) with: {'C': 2.0, 'kernel': 'poly'}\n",
      "#2 0.838889 (0.073373) with: {'C': 2.0, 'kernel': 'rbf'}\n",
      "#17 0.754678 (0.090977) with: {'C': 2.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de183768",
   "metadata": {},
   "source": [
    "Right now SVM is proving the best with accuracy of 84.9% over KNN's best of 83.9%. (But what about variance? KNN seemed to indicate a tighter variance during spot checking).\n",
    "\n",
    "Let's try some ensemble methods. No standardization on data this time. Because apparantly all four ensembles we are using are based on decision trees and thus are less sensitive to data distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5758145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembles\n",
    "ensembles = []\n",
    "# Boosting methods\n",
    "ensembles.append(('AB', AdaBoostClassifier()))\n",
    "ensembles.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "ensembles.append(('RF', RandomForestClassifier()))\n",
    "ensembles.append(('ET', ExtraTreesClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70c43878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.850877 (0.087719)\n",
      "GBM: 0.846199 (0.093313)\n",
      "RF: 0.814035 (0.070129)\n",
      "ET: 0.861111 (0.114918)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce268bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare ensemble algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Ensemble Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(8,6)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db14e0a",
   "metadata": {},
   "source": [
    "GBM might be worthy of further study, but for now SVM shows a lot of promise as a low complexity and stable model for this problem.\n",
    "\n",
    "Finalize Model with best parameters found during tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a3017",
   "metadata": {},
   "source": [
    "## prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e822fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = SVC(C=1.5) # rbf is default kernel\n",
    "model.fit(rescaledX , Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72e9f94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619047619048\n",
      "[[10  1]\n",
      " [ 1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.91      0.91      0.91        11\n",
      "           R       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.90      0.90      0.90        21\n",
      "weighted avg       0.90      0.90      0.90        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimate accuracy on validation set\n",
    "from pandas.plotting import scatter_matrix\n",
    "rescaledValidationX = scaler.transform(X_test)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb75b8",
   "metadata": {},
   "source": [
    "The accuracy on the validation set was 90.4%. Very high to our original estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e35eb851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'R', 'M', 'R', 'M', 'R',\n",
       "       'M', 'R', 'M', 'M', 'M', 'R', 'M', 'R'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b90556a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113    M\n",
       "23     R\n",
       "45     R\n",
       "81     R\n",
       "82     R\n",
       "109    M\n",
       "176    M\n",
       "134    M\n",
       "96     R\n",
       "98     M\n",
       "57     R\n",
       "169    M\n",
       "13     R\n",
       "204    M\n",
       "10     R\n",
       "161    M\n",
       "7      R\n",
       "172    M\n",
       "68     R\n",
       "102    M\n",
       "106    M\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a3fcf",
   "metadata": {},
   "source": [
    "## Testing model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d7b19",
   "metadata": {},
   "source": [
    "### Making Predictive System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbd79303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "The object is a mine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_data = (0.0307,0.0523,0.0653,0.0521,0.0611,0.0577,0.0665,0.0664,0.1460,0.2792,0.3877,0.4992,0.4981,0.4972,0.5607,0.7339,0.8230,0.9173,0.9975,0.9911,0.8240,0.6498,0.5980,0.4862,0.3150,0.1543,0.0989,0.0284,0.1008,0.2636,0.2694,0.2930,0.2925,0.3998,0.3660,0.3172,0.4609,0.4374,0.1820,0.3376,0.6202,0.4448,0.1863,0.1420,0.0589,0.0576,0.0672,0.0269,0.0245,0.0190,0.0063,0.0321,0.0189,0.0137,0.0277,0.0152,0.0052,0.0121,0.0124,0.0055)\n",
    "\n",
    "# changing the input_data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the np array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]=='R'):\n",
    "  print('The object is a Rock')\n",
    "else:\n",
    "  print('The object is a mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7993d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3736f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f17d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916afddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
